{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Imports\n",
    "\n",
    "import pandas as pd. Simply imports the library the current namespace, but rather than using the name pandas , it's instructed to use the name pd instead. This is just so you can do pd.Same with import numpy as np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "Pandas Series is a one-dimensional labeled array capable of holding data of any type (integer, string, float, python objects, etc.). \n",
    "\n",
    "The axis labels are collectively called index. Pandas Series is nothing but a column in an excel sheet.Labels need not be unique but must be a hashable type. The object supports both integer and label-based indexing and provides a host of methods for performing operations involving the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas uses something called a dataframe. It is a \n",
    "# 2D data structure that can hold multiple data types.\n",
    "# Columns have labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series are built on top of NumPy arrays. \n",
    "# Create a series by first creating a list\n",
    "list_1 = ['a', 'b', 'c', 'd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can define that I want the series indexes to be the provided labels\n",
    "labels = [1, 2, 3, 4]\n",
    "ser_1 = pd.Series(data=list_1, index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also add a NumPy array\n",
    "arr_1 = np.array([1, 2, 3, 4])\n",
    "ser_2 = pd.Series(arr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can quickly add labels and values with a dictionary\n",
    "dict_1 = {\"f_name\": \"Derek\", \"l_name\": \"Banas\", \"age\": 44}\n",
    "ser_3 = pd.Series(dict_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data by label\n",
    "ser_3[\"f_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can get the datatype\n",
    "ser_2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can perform math operations on series\n",
    "ser_2 + ser_2\n",
    "ser_2 - ser_2\n",
    "ser_2 * ser_2\n",
    "ser_2 / ser_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass them into NumPy methods\n",
    "# See NumPy tutorial for more math methods\n",
    "np.exp(ser_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between Series and ndarray is that operations\n",
    "# align by labels\n",
    "# Create a series from a dictionary\n",
    "ser_4 = pd.Series({4: 5, 5: 6, 6: 7, 7: 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If labels don't align you will get NaN\n",
    "ser_2 + ser_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can assign names to series\n",
    "ser_4 = pd.Series({8: 9, 9: 10}, name='rand_nums')\n",
    "ser_4.name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrames are the most commonly used data structure with Pandas. They are made up of multiple series that share the same index / label. They can contain multiple data types. They can be created from dicts, series, lists or other dataframes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random matrix 2x3 with values between 10 and 50\n",
    "arr_2 = np.random.randint(10, 50, size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DF with data, row labels & column labels\n",
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DF from multiple series in a dict\n",
    "# If series are of different lengthes extra spaces are NaN\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_dict accepts a column labels and lists\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can assign the keys as row labels and column labels separate\n",
    "# with orient='index'\n",
    "pd.DataFrame.from_dict(dict([('A', [1,2,3]), ('B', [4,5,6])]),orient='index', columns=['one','two','three'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of rows and columns as tuple\n",
    "print(df_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Editing & Retrieving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a column\n",
    "df_1['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get multiple columns\n",
    "df_1[['C', 'E']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabb a row as a series\n",
    "df_1.loc['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab row by index position\n",
    "df_1.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab cell with Row & Column\n",
    "df_1.loc['A', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab multiple cells by defining rows wanted & the\n",
    "# columns from those rows\n",
    "print(df_1.loc[['A', 'B'], ['D', 'E']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new column\n",
    "df_1['Total'] = df_1['C'] + df_1['D'] + df_1['E']\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can perform multiple calculations\n",
    "df_2['mult'] = df_2['one'] * df_2['two']\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new row by appending\n",
    "dict_2 = {'C': 44, 'D': 45, 'E': 46}\n",
    "new_row = pd.Series(dict_2, name='F')\n",
    "df_1 = df_1.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete column and set inplace to True which is required\n",
    "# because Pandas tries to help you not delete data\n",
    "# by accident\n",
    "df_1.drop('Total', axis=1, inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a row\n",
    "df_1.drop('B', axis=0, inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column and make it the index\n",
    "df_1['Sex'] = ['Men', 'Women']\n",
    "df_1.set_index('Sex', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can reset index values to numbers\n",
    "#df_1.reset_index(inplace=True)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign can be used to create a column while leaving the\n",
    "# original DF untouched\n",
    "df_2.assign(div=df_2['one'] / df_2['two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass in a function as well\n",
    "df_2.assign(div=lambda x: (x['one'] / x['two']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine DataFrames while keeping df_3 data unless\n",
    "# there is a NaN value\n",
    "df_3 = pd.DataFrame({'A': [1., np.nan, 3., np.nan]})\n",
    "df_4 = pd.DataFrame({'A': [8., 9., 2., 4.]})\n",
    "df_3.combine_first(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_2 = np.random.randint(10, 50, size=(2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(arr_2, ['A', 'B'], ['C', 'D', 'E'])\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use conditional operators to retrieve a table\n",
    "# based on the condition\n",
    "print(\"Greater than 40\\n\", df_1 > 40.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use comparison operater functions as well like\n",
    "# gt, lt, ge, le, eq, ne\n",
    "print(\"Greater than 45\\n\", df_1.gt(45.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can place conditions in brackets as well\n",
    "bool_1 = df_1 >= 45.0\n",
    "df_1[bool_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bools for a column\n",
    "df_1['E'] > 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a row if cell value in column matches a condition\n",
    "df_1[df_1['E']>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can focus on a column based on resulting dataframe\n",
    "df_2 = df_1[df_1['E']>30]\n",
    "df_2['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can stack these commands\n",
    "print(df_1[df_1['E']>20]['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also grab multiple columns\n",
    "print(df_1[df_1['E']>20][['C', 'D']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use multiple conditions\n",
    "arr_3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "df_2 = pd.DataFrame(arr_3, ['A', 'B', 'C'], ['X', 'Y', 'Z'])\n",
    "print(df_2, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use or | to combine conditions as well\n",
    "df_2[(df_2['X']>3) & (df_2['X']<7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Input / Output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can work with the following types of data : CSV, Plain Text, JSON, XML, PDF, SQL, HTML, XLSX, DOCX, ZIP, Images Hierarchical Data Format, MP3, and MP4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a CSV file\n",
    "# Type pd.read_ [TAB] to see the file types you can read\n",
    "cs_df = pd.read_csv('ComputerSales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a CSV file, but don't save the index as a column\n",
    "cs_df.to_csv('ComputerSalesBU.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can read data from Excel, but not formulas and macros\n",
    "pd.read_excel('Financial Sample.xlsx',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Excel\n",
    "cs_df.to_excel('ComputerSales.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if written\n",
    "pd.read_excel('ComputerSales.xlsx',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from MySQL Database\n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    # print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to table \n",
    "try:\n",
    "    db_connection = pymysql.connect(db='students', user='studentadmin', passwd='TurtleDove', host='localhost', port=3306)\n",
    "    # Used to issue queries\n",
    "    cursor = db_connection.cursor()\n",
    "    # Query to enter new student\n",
    "    insert_stmt = \"INSERT INTO students VALUES(NULL, 'Frank', 'Silva', 'fsilva@aol.com', '666 Hell St', 'Yakima', 'WA', 98901, '792-223-8966', '1959-2-22', 'M', NOW(), 3.50)\"\n",
    "    # Execute query\n",
    "    cursor.execute(insert_stmt)\n",
    "    # Commit changes to DB\n",
    "    db_connection.commit()\n",
    "    stud_df = pd.read_sql('SELECT * FROM students', con=db_connection)\n",
    "    print(stud_df)\n",
    "except Exception as e:\n",
    "    print(\"Exception : {}\".format(e))\n",
    "finally:\n",
    "    db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get 1 column of data \n",
    "cs_df_st = pd.read_csv('ComputerSales.csv', usecols=[\"State\"], squeeze=True)\n",
    "cs_df_st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics Techniques & Maths Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 1st 5 rows\n",
    "cs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last 5 rows\n",
    "cs_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1st 2\n",
    "cs_df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1st through 5 with a 2 step\n",
    "cs_df[:5:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indexes\n",
    "cs_df.index.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NumPy array\n",
    "cs_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get array from series\n",
    "ser_1.array\n",
    "\n",
    "dict_3 = {'one': pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "         'two': pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "df_2 = pd.DataFrame(dict_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can replace NaN values with 0 or anything else\n",
    "print(df_2.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values in row 2\n",
    "row = df_2.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add items in row 2 to all rows including row 2\n",
    "# You can do the same with sub, mul, and div\n",
    "df_2.add(row, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column 2\n",
    "col = df_2['two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract from other columns\n",
    "df_2.sub(col, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if empty\n",
    "df_2.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform executes a function on a dataframe\n",
    "df_5 = pd.DataFrame({'A': range(3), 'B': range(1, 4)})\n",
    "df_5.transform(lambda x: x+1)\n",
    "df_5.transform(lambda x: x**2)\n",
    "df_5.transform(lambda x: np.sqrt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can transform using multiple functions\n",
    "df_5.transform([lambda x: x**2, lambda x: x**3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing a dictionary allows you to perform different calculations\n",
    "# on different columns\n",
    "df_5.transform({'A': lambda x: x**2, 'B': lambda x: x**3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map performs a function on a series\n",
    "df_5['A'].map(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applymap does the same on a dataframe\n",
    "df_5.applymap(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values in column 2 of DF\n",
    "df_2['two'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of uniques\n",
    "df_2['two'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of times each value showed in column 2\n",
    "df_2['two'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names\n",
    "df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index info\n",
    "df_2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a DF that lists null values as True\n",
    "df_2.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby allows you to group rows based on a columnand perform a function\n",
    "# that combines those values (Aggregate Function)\n",
    "dict_5 = {'Store': [1,2,1,2], 'Flavor': ['Choc', 'Van', 'Straw', 'Choc'], 'Sales': [26, 12, 18, 22]}\n",
    "\n",
    "df_11 = pd.DataFrame(dict_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by the store number\n",
    "by_store = df_11.groupby('Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean sales by store\n",
    "by_store.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sales total just for store 1\n",
    "by_store.sum().loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use multiple functions of get a bunch\n",
    "by_store.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate, Merge & Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can concatenate DFs in the order DFs are provided\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],'B': [4,5,6]},index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],'B': [10,11,12]},index=[4,5,6])\n",
    "pd.concat([df_12, df_13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 2 DFs using their shared key column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],'B': [4,5,6],'key': [1,2,3]})\n",
    "df_13 = pd.DataFrame({'A': [7,8,9],'B': [10,11,12],'key': [1,2,3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner merges at the intersection of keys\n",
    "pd.merge(df_12, df_13, how='inner', on='key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how='left' or 'right' : Use keys from left or right frame\n",
    "# how='outer' : Use union of keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can join DFs with different indexes and instead of using \n",
    "# keys use a column\n",
    "df_12 = pd.DataFrame({'A': [1,2,3],'B': [4,5,6]},index=[1,2,3])\n",
    "df_13 = pd.DataFrame({'C': [7,8,9],'D': [10,11,12]},index=[1,4,5])\n",
    "df_12.join(df_13, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ice cream sales data\n",
    "ics_df = pd.read_csv('icecreamsales.csv')\n",
    "ics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total count of both columns\n",
    "ics_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipna skips null / NaN values\n",
    "ics_df.sum(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean for named column\n",
    "ics_df[\"Sales\"].mean()\n",
    "ics_df[\"Sales\"].median()\n",
    "ics_df[\"Sales\"].mode()\n",
    "ics_df[\"Sales\"].min()\n",
    "ics_df[\"Sales\"].max()\n",
    "ics_df[\"Sales\"].prod() # Product of values\n",
    "ics_df[\"Sales\"].std() # Standard deviation\n",
    "ics_df[\"Sales\"].var() # Variance\n",
    "ics_df[\"Sales\"].sem() # Standard error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative : Left long tail, Positive : Right long tail\n",
    "ics_df[\"Sales\"].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis : < 3 less outliers, 3 Normal Distribution, > 3 more outliers\n",
    "ics_df[\"Sales\"].kurt()\n",
    "ics_df[\"Sales\"].quantile(.5)\n",
    "ics_df[\"Sales\"].cumsum()\n",
    "ics_df[\"Sales\"].cumprod()\n",
    "ics_df[\"Sales\"].cummax()\n",
    "ics_df[\"Sales\"].cummin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple stats at once\n",
    "ics_df.describe()\n",
    "\n",
    "ser_dice = pd.Series(data=[2, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, \n",
    "                           6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8,\n",
    "                          8, 8, 9, 9, 9, 9, 10, 10, 10, 11, 11, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count for each value in series\n",
    "ser_dice.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can perform calculations on multiple columns using aggregate\n",
    "print(df_2)\n",
    "df_2.agg(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can do this with multiple functions\n",
    "df_2.agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over series\n",
    "ser_7 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "for col in ser_7:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over DFs\n",
    "arr_4 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_8 = pd.DataFrame(arr_4, ['B', 'C'], ['C', 'D', 'E'])\n",
    "print(df_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items allows you to iterate through key value pairs to make\n",
    "# calculations 1 column at a time\n",
    "for label, ser in df_8.items():\n",
    "    print(label)\n",
    "    print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also iterate through rows\n",
    "for index, row in df_8.iterrows():\n",
    "    print(f\"{index}\\n{row}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a tuple that contains row data\n",
    "for row in df_8.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting by index will return the same results if indexes\n",
    "# are in order, to reverse indexes mark ascending as False\n",
    "df_8.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by value for column D (Use the same function for series)\n",
    "df_8.sort_values(by='D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing Data to Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can pass DataFrames and Series into functions\n",
    "def get_profit_total(df):\n",
    "    prof_ser = df['Profit']\n",
    "    print(f\"Total Profit : {prof_ser.sum()}\")\n",
    "\n",
    "get_profit_total(cs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receives a DataFrame, splits the contact into new columns\n",
    "# being first and last name\n",
    "def split_name(df):\n",
    "    def get_names(full_name):\n",
    "        # Split contact at space\n",
    "        f_name, l_name = full_name.split()\n",
    "        # Create a series with first & last names in columns\n",
    "        # with those labels\n",
    "        return pd.Series(\n",
    "        (f_name, l_name),\n",
    "        index=['First Name', 'Last Name']\n",
    "        )\n",
    "    # apply() executes the function on all names in Contact column\n",
    "    names = df['Contact'].apply(get_names)\n",
    "    df[names.columns] = names\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function and display top 5 results\n",
    "split_name(cs_df).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will assign people to different age groups based on age\n",
    "def create_age_groups(df):\n",
    "    # Must have 1 more bins than labels\n",
    "    bins = [0, 30, 50, sys.maxsize]\n",
    "    # Group labels\n",
    "    labels = ['<30', '30-50', '>50']\n",
    "    \n",
    "    # cut puts values into certain groups based on intervals\n",
    "    # The group assigned to <30 has an age between 0 and 30\n",
    "    # between 30 & 50 is assigned 30-50 and so on\n",
    "    age_group = pd.cut(df['Age'], bins=bins, labels=labels)\n",
    "    # Create new column and return new dataframe info\n",
    "    df['Age Group'] = age_group\n",
    "    return df\n",
    "\n",
    "create_age_groups(cs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use a pipe to pass a dataframe to multiple functions\n",
    "cs_df.pipe(split_name).pipe(create_age_groups).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning, Reindexing and Renaming Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_6 = pd.Series(range(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "sl_1 = ser_6[:4]\n",
    "sl_2 = ser_6[1:]\n",
    "print(sl_1)\n",
    "print(sl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align both series by the union of their indexes\n",
    "sl_1.align(sl_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align by calling series\n",
    "sl_1.align(sl_2, join='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use passed series indexes\n",
    "sl_1.align(sl_2, join='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get where indexes intersect\n",
    "sl_1.align(sl_2, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use align with DFs as well\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_6 = pd.DataFrame(arr_3, ['A', 'B'], ['C', 'D', 'E'])\n",
    "arr_3 = np.random.randint(10, 50, size=(2, 3))\n",
    "df_7 = pd.DataFrame(arr_3, ['B', 'C'], ['C', 'D', 'E'])\n",
    "df_6\n",
    "df_6.align(df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindex allows you to align data by index\n",
    "ser_6.reindex(['c','b','a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same with DFs\n",
    "df_6.reindex(['B','A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop is very similar to reindex except it receives labels\n",
    "# you don't want to include\n",
    "df_6.drop(['A'], axis=0)\n",
    "df_6.drop(['D'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can rename labels\n",
    "df_6.rename(columns={'C': 'Men', 'D': 'Women', 'E': 'Pets'},\n",
    "           index={'A': 1, 'B': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-level indexing allows you to store data on multiple dimensions\n",
    "days = ['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2']\n",
    "meals = [1,2,3,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip pairs the days and meals arrays \n",
    "# Then we create a list of those paired tuples\n",
    "hier_index = list(zip(days, meals))\n",
    "print(hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts list of tuples into each row and column\n",
    "hier_index = pd.MultiIndex.from_tuples(hier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random array representing calories eaten per meal\n",
    "arr_5 = np.random.randint(500, 700, size=(6, 2))\n",
    "df_9 = pd.DataFrame(arr_5, hier_index, ['M', 'F'])\n",
    "print(df_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the day 1 DF\n",
    "df_9.loc['Day 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab 1st row as a series\n",
    "df_9.loc['Day 1'].loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab calories eaten by the female on day 2 for the 2nd meal\n",
    "df_9.loc['Day 2'].loc[2]['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign names to the Day and Meals Column\n",
    "df_9.index.names = ['Day', 'Meal']\n",
    "df_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a cross section\n",
    "# This gets me the Day 2 DF\n",
    "df_9.xs('Day 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get calories for the 1st meal for both days by saying what\n",
    "# meal index you want and the Meal column name\n",
    "df_9.xs(1, level='Meal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultiIndex out of a DF using a pivot table\n",
    "dict_6 = {'A':['Day 1', 'Day 1', 'Day 1', 'Day 2', 'Day 2', 'Day 2'],\n",
    "          'B': [1,2,3,1,2,3],\n",
    "          'C': ['M', 'F', 'M', 'F', 'M', 'F'],\n",
    "          'D': [1,2,3,4,5,6]}\n",
    "\n",
    "df_14 = pd.DataFrame(dict_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate the D column is the data\n",
    "# Make A & B a multilevel index\n",
    "# Define column names come from column C\n",
    "# You will have NaNs where data was missing\n",
    "df_14.pivot_table(values='D', index=['A','B'], columns=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_4 = {'A': [1,2,np.nan], 'B': [4, np.nan, np.nan], 'C': [7.,8.,9.]}\n",
    "df_10 = pd.DataFrame(dict_4)\n",
    "print(df_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing data from DF (Drops any row with missing values)\n",
    "df_10.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all columns with any missing data\n",
    "df_10.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row unless it has at least 2 non-NaN values\n",
    "df_10.dropna(thresh=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "df_10.fillna(value=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill A column with the mean of column\n",
    "df_10['A'].fillna(value=df_10['A'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with previous value\n",
    "df_10.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill with next value (Only works if there is a next value)\n",
    "df_10.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1st 5\n",
    "cs_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names\n",
    "print(cs_df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average profit per item\n",
    "cs_df['Profit'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the product with the highest profit\n",
    "cs_df[['Product ID', 'Profit']].max(axis=0).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of people who purchased from WV\n",
    "cs_df[cs_df['State']=='WV']['State'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of purchases in 2019\n",
    "len(cs_df[cs_df['Year']==2019].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of sales for each product type\n",
    "cs_df['Product ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of customers that bought a specific product\n",
    "cs_df[cs_df['Product ID']=='M01-F0024']['Contact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many made a website purchase for a profit over $200\n",
    "cs_df[(cs_df['Lead']=='Website') & (cs_df['Profit']>150)]['Lead'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out how many product profit amounts include .89 in cents\n",
    "cs_df['Profit'].apply(lambda cents: str(cents).split('.')[1]=='89').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library usef to create advanced static, animated and\n",
    "# interactive visualizations\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays matplotlib plots in the Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histograms provide an approximation of the distribution of results. You create them by dividing the range of values into bins or buckets. Then you count how many of the results fall into each bin. Rolls 2 dice 5000 times and charts the frequency and a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even though the odds increase as you approach 7 and then\n",
    "# decrease again (1 way to roll a 2 / 6 ways to roll a 7)\n",
    "# over many rolls they are nearly equal.\n",
    "df_dice = pd.DataFrame(np.random.randint(1,7,5000),columns = ['Hist'])\n",
    "\n",
    "df_dice['Odds'] = df_dice['Hist'] + np.random.randint(1,7,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha decreases the opacity in the chart\n",
    "ax = df_dice.plot.hist(bins=12, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic plot using 1000 random values that create cumulative sums\n",
    "# over an increasing date range\n",
    "ser_5 = pd.Series(np.random.randn(1000), index=pd.date_range('11/15/2017', periods=1000))\n",
    "ser_5 = ser_5.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_5.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 3 random plots\n",
    "df_15 = pd.DataFrame(np.random.randn(1000, 3),\n",
    "                    index=pd.date_range('11/15/2017', periods=1000),\n",
    "                    columns=list('ABC'))\n",
    "df_15 = df_15.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make bar chart from 5 random values\n",
    "# pd.DataFrame(np.random.randn(5)).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make MultiBar Charts\n",
    "vals = ['A', 'B', 'C', 'D']\n",
    "df_15 = pd.DataFrame(np.random.rand(10,4), columns=vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area plot \n",
    "# Define x range and y values\n",
    "x_rng = range(1,15)\n",
    "y_vals = [1,5,4,7,6,9,5,7,10,14,10,12,9,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change fill color and opacity\n",
    "plt.fill_between(x_rng, y_vals, color=\"skyblue\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area plot with multiple areas\n",
    "pd.DataFrame(np.random.rand(10,3), columns=['A','B','C']).plot.area()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatterplot with 100 random values\n",
    "pd.DataFrame(np.random.rand(100,2), columns=['A','B']).plot.scatter(x='A', y='B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple column scatter plots\n",
    "df_15 = pd.DataFrame(np.random.rand(50,4), columns=['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_15.plot.scatter(x='A', y='B', color='DarkBlue', label='Grp 1')\n",
    "\n",
    "df_15.plot.scatter(x='C', y='D', color='Orange', label='Grp 2', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Charts with 4 random values\n",
    "pd.Series(np.random.rand(4), index=['a','b','c','d'], name='Pie').plot.pie(figsize=(6,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
